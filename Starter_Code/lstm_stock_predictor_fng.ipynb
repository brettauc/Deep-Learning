{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Fear and Greed Index\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin fear and greed index values to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous fng values\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 0\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "# YOUR CODE HERE!\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split - 1]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split -1]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "# YOUR CODE HERE!\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(X)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "mms.fit(y)\n",
    "y_train = mms.transform(y_train)\n",
    "y_test = mms.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "# YOUR CODE HERE!\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "# YOUR CODE HERE!\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.25\n",
    "\n",
    "# L1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# L2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# L3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE!\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "# YOUR CODE HERE!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 371 samples\n",
      "Epoch 1/100\n",
      "371/371 [==============================] - 5s 13ms/sample - loss: 0.5645\n",
      "Epoch 2/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5611\n",
      "Epoch 3/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5565\n",
      "Epoch 4/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5560\n",
      "Epoch 5/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5552\n",
      "Epoch 6/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5646\n",
      "Epoch 7/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5829\n",
      "Epoch 8/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5792\n",
      "Epoch 9/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5757\n",
      "Epoch 10/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5750\n",
      "Epoch 11/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5701\n",
      "Epoch 12/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5744\n",
      "Epoch 13/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5692\n",
      "Epoch 14/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5691\n",
      "Epoch 15/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5652\n",
      "Epoch 16/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5675\n",
      "Epoch 17/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5640\n",
      "Epoch 18/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5635 0s \n",
      "Epoch 19/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5607\n",
      "Epoch 20/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5646\n",
      "Epoch 21/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5566\n",
      "Epoch 22/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5709\n",
      "Epoch 23/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5743\n",
      "Epoch 24/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5711\n",
      "Epoch 25/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5690\n",
      "Epoch 26/100\n",
      "371/371 [==============================] - 2s 6ms/sample - loss: 0.5678\n",
      "Epoch 27/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5653\n",
      "Epoch 28/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5630\n",
      "Epoch 29/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5615\n",
      "Epoch 30/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5611\n",
      "Epoch 31/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5634\n",
      "Epoch 32/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5592\n",
      "Epoch 33/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5566\n",
      "Epoch 34/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5557\n",
      "Epoch 35/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5574\n",
      "Epoch 36/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5571\n",
      "Epoch 37/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5529\n",
      "Epoch 38/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5591\n",
      "Epoch 39/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5583\n",
      "Epoch 40/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5537\n",
      "Epoch 41/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5559\n",
      "Epoch 42/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5562\n",
      "Epoch 43/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5548\n",
      "Epoch 44/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5564\n",
      "Epoch 45/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5550\n",
      "Epoch 46/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5566\n",
      "Epoch 47/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5611\n",
      "Epoch 48/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5589\n",
      "Epoch 49/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5577\n",
      "Epoch 50/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5544\n",
      "Epoch 51/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5626\n",
      "Epoch 52/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5764\n",
      "Epoch 53/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5638\n",
      "Epoch 54/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5588\n",
      "Epoch 55/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5590\n",
      "Epoch 56/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5566\n",
      "Epoch 57/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5571\n",
      "Epoch 58/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5553 \n",
      "Epoch 59/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5522\n",
      "Epoch 60/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5531\n",
      "Epoch 61/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5558\n",
      "Epoch 62/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5522\n",
      "Epoch 63/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5534\n",
      "Epoch 64/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5517\n",
      "Epoch 65/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5514 1s - loss: 0.6 -\n",
      "Epoch 66/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5693\n",
      "Epoch 67/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5649\n",
      "Epoch 68/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5568\n",
      "Epoch 69/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5581\n",
      "Epoch 70/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5526\n",
      "Epoch 71/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5518\n",
      "Epoch 72/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5558\n",
      "Epoch 73/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5514\n",
      "Epoch 74/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5523\n",
      "Epoch 75/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5514\n",
      "Epoch 76/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5511\n",
      "Epoch 77/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5560\n",
      "Epoch 78/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5548\n",
      "Epoch 79/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5552\n",
      "Epoch 80/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5553\n",
      "Epoch 81/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5529\n",
      "Epoch 82/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5512\n",
      "Epoch 83/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5538\n",
      "Epoch 84/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5539\n",
      "Epoch 85/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5511\n",
      "Epoch 86/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5562\n",
      "Epoch 87/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5561\n",
      "Epoch 88/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5541\n",
      "Epoch 89/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5539\n",
      "Epoch 90/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5520\n",
      "Epoch 91/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5522\n",
      "Epoch 92/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5526\n",
      "Epoch 93/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5513\n",
      "Epoch 94/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5510\n",
      "Epoch 95/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5592\n",
      "Epoch 96/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5565\n",
      "Epoch 97/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5579\n",
      "Epoch 98/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5573\n",
      "Epoch 99/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5535\n",
      "Epoch 100/100\n",
      "371/371 [==============================] - 2s 5ms/sample - loss: 0.5524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df45f4ea48>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "model.fit(X_train, y_train, epochs=100, shuffle=False, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 5ms/sample - loss: 0.6714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7576573610305786"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# YOUR CODE HERE!\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "# YOUR CODE HERE!\n",
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = mms.inverse_transform(predict)\n",
    "real_prices = mms.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>9394.678711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>9221.561523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>3937.040039</td>\n",
       "      <td>9036.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-23</th>\n",
       "      <td>3983.530029</td>\n",
       "      <td>9013.931641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>4149.089844</td>\n",
       "      <td>9018.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-02-20  3924.239990  9394.678711\n",
       "2019-02-21  3974.050049  9221.561523\n",
       "2019-02-22  3937.040039  9036.296875\n",
       "2019-02-23  3983.530029  9013.931641\n",
       "2019-02-24  4149.089844  9018.312500"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='11396'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"e1b32e6e-84ce-4fd2-b84c-d5c23bf57eb9\" data-root-id=\"11396\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "  var docs_json = {\"e4aa3353-abbc-4d30-84db-4ddd0c5ad132\":{\"roots\":{\"references\":[{\"attributes\":{\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11439\",\"type\":\"Line\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"11450\"},{\"id\":\"11451\"},{\"id\":\"11452\"},{\"id\":\"11453\"},{\"id\":\"11454\"},{\"id\":\"11455\"},{\"id\":\"11456\"},{\"id\":\"11457\"},{\"id\":\"11458\"},{\"id\":\"11459\"},{\"id\":\"11460\"},{\"id\":\"11461\"}]},\"id\":\"11412\",\"type\":\"DatetimeTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"11436\"},\"glyph\":{\"id\":\"11439\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"11441\"},\"nonselection_glyph\":{\"id\":\"11440\"},\"selection_glyph\":null,\"view\":{\"id\":\"11443\"}},\"id\":\"11442\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11440\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"11424\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"11455\",\"type\":\"DaysTicker\"},{\"attributes\":{\"end\":13831.480297400001,\"reset_end\":13831.480297400001,\"reset_start\":2813.0800046,\"start\":2813.0800046,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"11399\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"Price\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"11434\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"11416\"}},\"id\":\"11415\",\"type\":\"LinearAxis\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"11456\",\"type\":\"DaysTicker\"},{\"attributes\":{\"align\":null,\"below\":[{\"id\":\"11411\"}],\"center\":[{\"id\":\"11414\"},{\"id\":\"11418\"}],\"left\":[{\"id\":\"11415\"}],\"margin\":null,\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"plot_height\":300,\"plot_width\":700,\"renderers\":[{\"id\":\"11442\"},{\"id\":\"11470\"}],\"right\":[{\"id\":\"11462\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"11403\"},\"toolbar\":{\"id\":\"11425\"},\"x_range\":{\"id\":\"11398\"},\"x_scale\":{\"id\":\"11407\"},\"y_range\":{\"id\":\"11399\"},\"y_scale\":{\"id\":\"11409\"}},\"id\":\"11402\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"11434\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"11479\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"11459\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"axis_label\":\"Date\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"11432\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"11412\"}},\"id\":\"11411\",\"type\":\"DatetimeAxis\"},{\"attributes\":{},\"id\":\"11407\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"11464\"},\"glyph\":{\"id\":\"11467\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"11469\"},\"nonselection_glyph\":{\"id\":\"11468\"},\"selection_glyph\":null,\"view\":{\"id\":\"11471\"}},\"id\":\"11470\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"11437\",\"type\":\"Selection\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer13563\",\"sizing_mode\":\"stretch_width\"},\"id\":\"11669\",\"type\":\"Spacer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11468\",\"type\":\"Line\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"11400\"},{\"id\":\"11419\"},{\"id\":\"11420\"},{\"id\":\"11421\"},{\"id\":\"11422\"},{\"id\":\"11423\"}]},\"id\":\"11425\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"11411\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"11414\",\"type\":\"Grid\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"11457\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"11442\"},{\"id\":\"11470\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"11400\",\"type\":\"HoverTool\"},{\"attributes\":{\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11467\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"11416\",\"type\":\"BasicTicker\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"11454\",\"type\":\"DaysTicker\"},{\"attributes\":{\"axis\":{\"id\":\"11415\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"11418\",\"type\":\"Grid\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer13562\",\"sizing_mode\":\"stretch_width\"},\"id\":\"11397\",\"type\":\"Spacer\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"11442\"}]},\"id\":\"11463\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11469\",\"type\":\"Line\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"11453\",\"type\":\"DaysTicker\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"11470\"}]},\"id\":\"11492\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"11419\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"11465\",\"type\":\"Selection\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"vCL433qorkBmxAWgGQyvQCHn/X8Uwq5A3Qn2Xw8fr0C+MQQAFzWwQGS1+X89d61ARN0HIAULrkCcSgaAwtOtQCP2CaBw7a1AZLX5f73erUB3RfC/9e6tQFZe8j/hBa5AqqENwJ7IrUDdCfZfjyatQAIPDCBcRK5Ad0Xwv/VFrkAf2PFfOFWuQIm6D0AKOK5AvCL433rXrkCHqwMgrrOuQOEnDqDHRa5A//Dz3yNhrkBVXvI/4UyuQFZe8j/hUq5AQs77/yiurkBE3QcgBXavQAAAAAAAPK9AyogLQLMpr0DhJw6gR3CvQAAAAACAsa9AAg8MINw5r0CHqwMgrkGvQN8YAoBrTq9AH9jxXzg0r0BnxAWgGamuQCP2CaBwzK5Ad0Xwv/Wbr0CbO/pf5oivQE4lA0BhD7BATiUDQCEWsEArL/mfsBCwQHpU/N9RN7BAhqsDIO4qs0C/MQQAl3CzQAtI+x9cMbNAvCL43zq3s0AAAAAAQMGzQELO+/8oUbRAvjEEABeutEAtPgXATFG0QGXEBaCZxrRA1dAGYI+4s0D/////f9mzQELO+/+o2LNAvjEEAJcttEBD3QcgRa2zQNXQBmDPXLRAnEoGgEJ0tED/////v6m0QOlg/Z+Hr7RAhqsDIC7OtEBktfl/vbm0QN8YAoCrErVAZcQFoBmjtUAh5/1/lE61QOAYAoCrKrRAvjEEABdytEC7Ivjfem20QNPB+j9zmLRAbwwBwPV1tED1twTgo+a0QJHz/j+KDbVAF58CYLh8tUBOJQNAYXm2QCHn/X8U0LZA9rcE4COitkDfGAKAK3S2QHpU/N+Ru7ZAbwwBwLVut0BvDAHA9Ru4QJHz/j9K1rhACkj7H1wXvEBOJQNAoUG7QApI+x9cfr5ATiUDQCEsv0Ag5/1/1Pe/QApI+x8cwr5AbwwBwPXLvEAh5/1/FGK8QHpU/N+RAMBAkfP+P0o+v0CHqwMg7gu/QPa3BODjyr1AAAAAAIDEvkCaO/pfZjy/QE4lA0Ahe79A3xgCgB0LwUBvDAHAlSjBQLLa/L9sB8FA6WD9n0fswED/////HyrAQG8MAcBVs8BAWW3+X++1wEAg5/1/9BDBQGS1+X99sr9AF58CYHj9vUCR8/4/Sm++QApI+x9cf75ATyUDQKFCv0DpYP2fx/2+QCwv+Z9w271AAAAAAABVv0B5VPzfUe2+QPW3BOAj7r9AvjEEAMkVwEA4hgDg+vrAQOlg/Z/HSsFAvjEEAJeJwUBOJQNAATzCQDiGAODavMFAyHn/H0UgwkCy2vy/bKDCQFlt/l9v9cNAyHn/H8XgxECy2vy//jPFQLLa/L/ejcVA3xgCgCvuxkB6VPzfozjJQOAYAoALycVA6WD9n4chyECz2vy/DDbHQBefAmCGCMVAWG3+X++vxECnkgGgEC7FQIarAyDOZsdAIef9f0LKxUAAAAAAoHjFQBefAmB4+MVAeVT83yNpxkAi5/1/FATIQCHn/X+Ci8hAWW3+X4+hx0BZbf5fjyfGQFlt/l+vCsdAhqsDIPwxxkAh5/1/NO7DQE4lA0AhMcVAFp8CYLhnwkBOJQNAE/DCQLLa/L8sx8RAF58CYHiSxEBwDAHAtQPFQDiGAOBarcRAWW3+X+8qxEBOJQNAEz/DQHtU/N8RFsNAvjEEADdNw0DpYP2fuTvDQL4xBAApg8JAIOf9f+KdwkA=\",\"dtype\":\"float64\",\"shape\":[160]}},\"selected\":{\"id\":\"11437\"},\"selection_policy\":{\"id\":\"11479\"}},\"id\":\"11436\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"11432\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"11460\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"11423\",\"type\":\"ResetTool\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkIAAED6srB2QgAAAGAFsXZCAADAxVexdkIAAIArqrF2QgAAQJH8sXZCAAAA906ydkIAAMBcobJ2QgAAgMLzsnZCAABAKEazdkIAAACOmLN2QgAAwPPqs3ZCAACAWT20dkIAAEC/j7R2QgAAACXitHZCAADAijS1dkIAAIDwhrV2QgAAQFbZtXZCAAAAvCu2dkIAAMAhfrZ2QgAAgIfQtnZCAABA7SK3dkIAAABTdbd2QgAAwLjHt3ZCAACAHhq4dkIAAECEbLh2QgAAAOq+uHZCAADATxG5dkIAAIC1Y7l2QgAAQBu2uXZCAAAAgQi6dkIAAMDmWrp2QgAAgEytunZCAABAsv+6dkIAAAAYUrt2QgAAwH2ku3ZCAACA4/a7dkIAAEBJSbx2QgAAAK+bvHZCAADAFO68dkIAAIB6QL12QgAAQOCSvXZCAAAARuW9dkIAAMCrN752QgAAgBGKvnZCAABAd9y+dkIAAADdLr92QgAAwEKBv3ZCAACAqNO/dkIAAEAOJsB2QgAAAHR4wHZCAADA2crAdkIAAIA/HcF2QgAAQKVvwXZCAAAAC8LBdkIAAMBwFMJ2QgAAgNZmwnZCAABAPLnCdkIAAACiC8N2QgAAwAdew3ZCAACAbbDDdkI=\",\"dtype\":\"float64\",\"shape\":[160]},\"value\":{\"__ndarray__\":\"t8oSRj8WEEYwMQ1GutcMRkDpDEYk/ARGlNsIRkJFBka0XAhGBhgPRjz6EUaSKhFGgWwZRuL1D0ZUzhNGMREMRhOm80XdbxlGEs4VRmH2GkYogRlGX+8aRthgEUZZ8YJFNWeVRVym9UVwZ+9FbaDaRQ9d5EUPLOdFnc/rRTBs80X6XAFGuTP8RayyB0Z1cgVGKX0HRjvWBEaYiw1GppcQRrEJF0b7cv1F+ZT9RW9g6EU/KANGyUwERu1ZD0Zv8BhGaxEcRiMRHEalqxhGQuQcRjHoGUbplxJGsE8PRmLgDEYTuRNGYdwHRpH8Dka+1hZGgxsfRmjLGUZGuR5GqF4cRnqbIEYoqRpGreH2RWVZAEaazAdGxUQFRvxED0ZsrAJG9y4WRv7XDUaTDBNGh48XRgwRB0ZE5wFGeUARRo4QEEY50BRGGzkZRl9fHUadgR5GEsAdRiWeI0Zi3RhGapoaRr+fDUZGWRNGTusTRoONGkY6mRZGNQgXRoRrGkZoJhdGE3McRpU1DUaWshdGbCMURtSdHkZCSRBG5qQPRjRBE0Ze1gxGnm0TRnJTDkag/wxGtCYHRrHhCEbhNRVGCUghRl6+IUb/tiVGm6shRifPIkaQtyRGvh4lRtelI0Z7OCVG4bImRpawDUbAEQ9GO5MNRsJ9EkasCxVGMgMZRmNPHEaoPyFGTOQgRpw0HUbdOx1Gd2EkRg6rJEYeliVG6oslRmwmJUb7BiZGOoYnRu/dFUbMYiFGUV8jRqxVH0ZTZRNG3gETRkDrIEbRZRZGWZUURjEmGEZmVxJGJvQWRtroAkYXy+1FAlGyRcqJsEWaOuRFb+0FRk+HCEbS4c5FgrniRQ==\",\"dtype\":\"float32\",\"shape\":[160]}},\"selected\":{\"id\":\"11465\"},\"selection_policy\":{\"id\":\"11502\"}},\"id\":\"11464\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"11458\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"end\":1564358400000.0,\"reset_end\":1564358400000.0,\"reset_start\":1550620800000.0,\"start\":1550620800000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"11398\",\"type\":\"Range1d\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"11452\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"11461\",\"type\":\"YearsTicker\"},{\"attributes\":{\"children\":[{\"id\":\"11397\"},{\"id\":\"11402\"},{\"id\":\"11669\"}],\"margin\":[0,0,0,0],\"name\":\"Row13558\",\"tags\":[\"embedded\"]},\"id\":\"11396\",\"type\":\"Row\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"11451\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"source\":{\"id\":\"11436\"}},\"id\":\"11443\",\"type\":\"CDSView\"},{\"attributes\":{\"source\":{\"id\":\"11464\"}},\"id\":\"11471\",\"type\":\"CDSView\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"11463\"},{\"id\":\"11492\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"11462\",\"type\":\"Legend\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"11441\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"11409\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"11420\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"11502\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"11450\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"11421\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":\"\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12pt\"}},\"id\":\"11403\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"11424\"}},\"id\":\"11422\",\"type\":\"BoxZoomTool\"}],\"root_ids\":[\"11396\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"e4aa3353-abbc-4d30-84db-4ddd0c5ad132\",\"root_ids\":[\"11396\"],\"roots\":{\"11396\":\"e1b32e6e-84ce-4fd2-b84c-d5c23bf57eb9\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 283,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "11396"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "# YOUR CODE HERE!\n",
    "stocks.hvplot.line(xlabel=\"Date\",\n",
    "                  ylabel=\"Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
